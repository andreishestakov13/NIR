{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4a74c4e-25a9-4faa-a9b7-79e96c0bada1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pathlib\n",
    "import string\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "\n",
    "import torch\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KDTree\n",
    "\n",
    "from base import BaseDataset\n",
    "from models import Segmentation\n",
    "\n",
    "\n",
    "class AttrDict(dict):\n",
    "    __getattr__ = dict.__getitem__\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2b4c3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_from_letter(fnm_list, n_items, case = None):\n",
    "    #case: ('lower','upper')\n",
    "    df = pd.DataFrame()\n",
    "    df['fname'] = [fnm.split('.')[0] for fnm in fnm_list]\n",
    "    spl = df.fname.str.split('_')\n",
    "    df['letter'] = spl.apply(lambda x: x[0])\n",
    "    df['case'] = spl.apply(lambda x: x[-1])\n",
    "    df['class'] = df['letter']+df['case']\n",
    "    df['class'] = pd.Categorical(df['class'])\n",
    "    df['label'] = df['class'].cat.codes    \n",
    "\n",
    "    n_classes = df['class'].nunique()\n",
    "    \n",
    "    if case is not None:\n",
    "        df = df[df.case == case]\n",
    "    samples = df.groupby('label').apply(lambda x: x.sample(n_items))\n",
    "    fnm_labels = samples[['fname','label']].set_index('fname').label.to_dict()\n",
    "    return n_classes, fnm_labels\n",
    "\n",
    "class RankingDataset(BaseDataset):\n",
    "    @staticmethod\n",
    "    def num_classes():\n",
    "        return self.num_classes\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        root_dir,\n",
    "        fnm_labels,\n",
    "        num_classes,\n",
    "        _center_and_scale=True,\n",
    "        random_rotate=False,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            _center_and_scale (bool, optional): Whether to center and scale the solid. Defaults to True.\n",
    "            random_rotate (bool, optional): Whether to apply random rotations to the solid in 90 degree increments. Defaults to False.\n",
    "        \"\"\"\n",
    "        # path = pathlib.Path(root_dir)\n",
    "        self.random_rotate = random_rotate\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        self.lbs = fnm_labels\n",
    "\n",
    "        file_paths = [pathlib.Path(root_dir+fnm+'.bin') for fnm in fnm_labels.keys()]\n",
    "        print(file_paths[0], file_paths[0].exists())\n",
    "        self.load_graphs(file_paths, _center_and_scale)\n",
    "        print(\"Done loading {} files\".format(len(self.data)))\n",
    "\n",
    "    def load_one_graph(self, file_path):\n",
    "        # Load the graph using base class method\n",
    "        sample = super().load_one_graph(file_path)\n",
    "        # Additionally get the label from the filename and store it in the sample dict\n",
    "\n",
    "        sample[\"label\"] = torch.tensor([self.lbs[str(file_path.stem)]]).long()\n",
    "        return sample\n",
    "\n",
    "    def _collate(self, batch):\n",
    "        collated = super()._collate(batch)\n",
    "        collated[\"label\"] =  torch.cat([x[\"label\"] for x in batch], dim=0)\n",
    "        return collated\n",
    "    \n",
    "def encode(model, loader, device):\n",
    "    embs_list = []\n",
    "    labels_list = []\n",
    "    with torch.no_grad():  \n",
    "        for batch in loader:\n",
    "            inputs = batch[\"graph\"].to(device)\n",
    "            inputs.ndata[\"x\"] = inputs.ndata[\"x\"].permute(0, 3, 1, 2)\n",
    "            inputs.edata[\"x\"] = inputs.edata[\"x\"].permute(0, 2, 1)\n",
    "            embs_list.append(model.encode_part(inputs).to(device=torch.device('cpu')))\n",
    "                        \n",
    "            labels_list.append(batch[\"label\"].to(device=torch.device('cpu')))\n",
    "    return embs_list, labels_list\n",
    "\n",
    "def cals_map_all(test_loaders, model, device):\n",
    "    model = model.eval()\n",
    "    metr = []\n",
    "    for loader in test_loaders:\n",
    "        e_list, l_list = encode(model, loader, device)\n",
    "        embs = torch.cat(e_list,dim=0).numpy()\n",
    "        lbs = torch.cat(l_list,dim=0).numpy()\n",
    "        metr.append(calc_map(embs, lbs))\n",
    "    return np.mean(metr)\n",
    "\n",
    "def calc_map(X, labels, K = 5):\n",
    "    tree = KDTree(X, leaf_size=40)  # creating kd tree\n",
    "    _, ind = tree.query(X, k=K+1)  # quering nearest items\n",
    "\n",
    "    is_valid_label = (labels[ind[:,1:]] == labels.reshape(-1,1)).astype(int)\n",
    "\n",
    "    cum_sum = np.cumsum(is_valid_label, axis=1)\n",
    "    P_K = cum_sum/np.arange(1, K+1).reshape(1,-1)\n",
    "    AP_K = P_K.sum(axis=1) / np.clip(cum_sum[:,-1],1, K)\n",
    "\n",
    "    return AP_K.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "482843fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 1.12.1\n",
      "Is CUDA enabled? False\n"
     ]
    }
   ],
   "source": [
    "#!conda install pytorch==1.11.0 cudatoolkit=11.3 -c pytorch\n",
    "print(\"Torch version:\",torch.__version__)\n",
    "\n",
    "print(\"Is CUDA enabled?\",torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17144a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu113\n",
      "Requirement already satisfied: torch==1.11.0+cu113 in c:\\users\\new\\appdata\\roaming\\python\\python39\\site-packages (1.11.0+cu113)\n",
      "Collecting torchvision==0.12.0+cu113\n",
      "  Using cached https://download.pytorch.org/whl/cu113/torchvision-0.12.0%2Bcu113-cp39-cp39-win_amd64.whl (5.4 MB)\n",
      "Collecting torchaudio==0.11.0\n",
      "  Using cached https://download.pytorch.org/whl/cu113/torchaudio-0.11.0%2Bcu113-cp39-cp39-win_amd64.whl (573 kB)\n",
      "Requirement already satisfied: typing-extensions in d:\\anaconda\\envs\\uv_net\\lib\\site-packages (from torch==1.11.0+cu113) (4.7.1)\n",
      "Requirement already satisfied: numpy in d:\\anaconda\\envs\\uv_net\\lib\\site-packages (from torchvision==0.12.0+cu113) (1.25.2)\n",
      "Requirement already satisfied: requests in d:\\anaconda\\envs\\uv_net\\lib\\site-packages (from torchvision==0.12.0+cu113) (2.31.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in d:\\anaconda\\envs\\uv_net\\lib\\site-packages (from torchvision==0.12.0+cu113) (9.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\anaconda\\envs\\uv_net\\lib\\site-packages (from requests->torchvision==0.12.0+cu113) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda\\envs\\uv_net\\lib\\site-packages (from requests->torchvision==0.12.0+cu113) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\anaconda\\envs\\uv_net\\lib\\site-packages (from requests->torchvision==0.12.0+cu113) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\envs\\uv_net\\lib\\site-packages (from requests->torchvision==0.12.0+cu113) (2023.7.22)\n",
      "Installing collected packages: torchvision, torchaudio\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.11.2+cu102\n",
      "    Uninstalling torchvision-0.11.2+cu102:\n",
      "      Successfully uninstalled torchvision-0.11.2+cu102\n",
      "  Attempting uninstall: torchaudio\n",
      "    Found existing installation: torchaudio 0.10.1+cu102\n",
      "    Uninstalling torchaudio-0.10.1+cu102:\n",
      "      Successfully uninstalled torchaudio-0.10.1+cu102\n",
      "Successfully installed torchaudio-0.11.0+cu113 torchvision-0.12.0+cu113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\new\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\new\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -qdm (d:\\anaconda\\envs\\uv_net\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\new\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -qdm (d:\\anaconda\\envs\\uv_net\\lib\\site-packages)\n",
      "DEPRECATION: vtk -PKG-VERSION has a non-standard version number. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of vtk or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\new\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\new\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\new\\appdata\\roaming\\python\\python39\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch==1.11.0+cu113 torchvision==0.12.0+cu113 torchaudio==0.11.0 --extra-index-url https://download.pytorch.org/whl/cu113 --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6cd07aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\pytorch_lightning\\utilities\\migration\\migration.py:195: PossibleUserWarning: You have multiple `ModelCheckpoint` callback states in this checkpoint, but we found state keys that would end up colliding with each other after an upgrade, which means we can't differentiate which of your checkpoint callbacks needs which states. At least one of your `ModelCheckpoint` callbacks will not be able to reload the state.\n",
      "  rank_zero_warn(\n",
      "Lightning automatically upgraded your loaded checkpoint from v1.3.8 to v1.9.0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file D:\\NIR\\best.ckpt`\n"
     ]
    }
   ],
   "source": [
    "args = AttrDict({})\n",
    "args.batch_size = 4\n",
    "args.random_rotate = False\n",
    "args.num_workers = 0\n",
    "args.checkpoint = 'D:/NIR/best.ckpt'\n",
    "device = torch.device('cpu') #изначально было ('cuda:2'), может потом стоит поменять обратно, если чет не будет получаться опять\n",
    "\n",
    "model = Segmentation.load_from_checkpoint(args.checkpoint).model.to(device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f835562f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\NIR\\SolidLetters\\graph_with_eattr\\a_Rhodium Libre_lower.bin True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/52 [00:00<?, ?it/s]D:\\anaconda\\lib\\site-packages\\dgl\\data\\graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.\n",
      "  dgl_warning(\n",
      "100%|██████████| 52/52 [00:00<00:00, 795.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done loading 52 files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\NIR\\SolidLetters\\graph_with_eattr\\a_Love Ya Like A Sister_upper.bin True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/52 [00:00<?, ?it/s]D:\\anaconda\\lib\\site-packages\\dgl\\data\\graph_serialize.py:189: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.\n",
      "  dgl_warning(\n",
      "100%|██████████| 52/52 [00:00<00:00, 892.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done loading 52 files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "fnm_list = os.listdir('D:/NIR/SolidLetters/graph_with_eattr')\n",
    "N_ITEMS_PER_CLASS = 2\n",
    "\n",
    "# creating loaders for SolidLetters dataset quering\n",
    "test_loaders = []\n",
    "for case in ('lower', 'upper'):\n",
    "    ncl, fnm_labels = sample_from_letter(fnm_list, N_ITEMS_PER_CLASS, case)\n",
    "    dset = RankingDataset('D:/NIR/SolidLetters/graph_with_eattr/', \n",
    "                           fnm_labels, \n",
    "                           ncl)\n",
    "    test_loaders.append(dset.get_dataloader(batch_size=args.batch_size, shuffle=False, num_workers=args.num_workers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a2f7c3d0",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'UVNetSegmenter' object has no attribute 'encode_part'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# calculating metric\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mcals_map_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_loaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[7], line 79\u001b[0m, in \u001b[0;36mcals_map_all\u001b[1;34m(test_loaders, model, device)\u001b[0m\n\u001b[0;32m     77\u001b[0m metr \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m loader \u001b[38;5;129;01min\u001b[39;00m test_loaders:\n\u001b[1;32m---> 79\u001b[0m     e_list, l_list \u001b[38;5;241m=\u001b[39m \u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     80\u001b[0m     embs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(e_list,dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m     81\u001b[0m     lbs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(l_list,dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "Cell \u001b[1;32mIn[7], line 70\u001b[0m, in \u001b[0;36mencode\u001b[1;34m(model, loader, device)\u001b[0m\n\u001b[0;32m     68\u001b[0m         inputs\u001b[38;5;241m.\u001b[39mndata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mndata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     69\u001b[0m         inputs\u001b[38;5;241m.\u001b[39medata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39medata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 70\u001b[0m         embs_list\u001b[38;5;241m.\u001b[39mappend(\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode_part\u001b[49m(inputs)\u001b[38;5;241m.\u001b[39mto(device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)))\n\u001b[0;32m     72\u001b[0m         labels_list\u001b[38;5;241m.\u001b[39mappend(batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)))\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m embs_list, labels_list\n",
      "File \u001b[1;32mD:\\anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py:1207\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1205\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[0;32m   1206\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[1;32m-> 1207\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   1208\u001b[0m     \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, name))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'UVNetSegmenter' object has no attribute 'encode_part'"
     ]
    }
   ],
   "source": [
    "# calculating metric\n",
    "cals_map_all(test_loaders, model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11312568",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b78ed1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104f911e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366fdaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pathlib\n",
    "import string\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "import torch\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KDTree\n",
    "\n",
    "from base1 import BaseDataset\n",
    "from models1 import Classification\n",
    "\n",
    "\n",
    "class AttrDict(dict):\n",
    "    __getattr__ = dict.__getitem__\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83212ff1-1cb2-4bc8-8eee-91efd4951240",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_from_letter(fnm_list, n_items, case = None):\n",
    "    #case: ('lower','upper')\n",
    "    df = pd.DataFrame()\n",
    "    df['fname'] = [fnm.split('.')[0] for fnm in fnm_list]\n",
    "    spl = df.fname.str.split('_')\n",
    "    df['letter'] = spl.apply(lambda x: x[0])\n",
    "    df['case'] = spl.apply(lambda x: x[-1])\n",
    "    df['class'] = df['letter']+df['case']\n",
    "    df['class'] = pd.Categorical(df['class'])\n",
    "    df['label'] = df['class'].cat.codes    \n",
    "\n",
    "    n_classes = df['class'].nunique()\n",
    "    \n",
    "    if case is not None:\n",
    "        df = df[df.case == case]\n",
    "    samples = df.groupby('label').apply(lambda x: x.sample(n_items))\n",
    "    fnm_labels = samples[['fname','label']].set_index('fname').label.to_dict()\n",
    "    return n_classes, fnm_labels\n",
    "\n",
    "class RankingDataset(BaseDataset):\n",
    "    @staticmethod\n",
    "    def num_classes():\n",
    "        return self.num_classes\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        root_dir,\n",
    "        fnm_labels,\n",
    "        num_classes,\n",
    "        _center_and_scale=True,\n",
    "        random_rotate=False,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            _center_and_scale (bool, optional): Whether to center and scale the solid. Defaults to True.\n",
    "            random_rotate (bool, optional): Whether to apply random rotations to the solid in 90 degree increments. Defaults to False.\n",
    "        \"\"\"\n",
    "        # path = pathlib.Path(root_dir)\n",
    "        self.random_rotate = random_rotate\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        self.lbs = fnm_labels\n",
    "\n",
    "        file_paths = [pathlib.Path(root_dir+fnm+'.bin') for fnm in fnm_labels.keys()]\n",
    "        print(file_paths[0], file_paths[0].exists())\n",
    "        self.load_graphs(file_paths, _center_and_scale)\n",
    "        print(\"Done loading {} files\".format(len(self.data)))\n",
    "\n",
    "    def load_one_graph(self, file_path):\n",
    "        # Load the graph using base class method\n",
    "        sample = super().load_one_graph(file_path)\n",
    "        # Additionally get the label from the filename and store it in the sample dict\n",
    "\n",
    "        sample[\"label\"] = torch.tensor([self.lbs[str(file_path.stem)]]).long()\n",
    "        return sample\n",
    "\n",
    "    def _collate(self, batch):\n",
    "        collated = super()._collate(batch)\n",
    "        collated[\"label\"] =  torch.cat([x[\"label\"] for x in batch], dim=0)\n",
    "        return collated\n",
    "    \n",
    "def encode(model, loader, device):\n",
    "    embs_list = []\n",
    "    labels_list = []\n",
    "    with torch.no_grad():  \n",
    "        for batch in loader:\n",
    "            inputs = batch[\"graph\"].to(device)\n",
    "            inputs.ndata[\"x\"] = inputs.ndata[\"x\"].permute(0, 3, 1, 2)\n",
    "            inputs.edata[\"x\"] = inputs.edata[\"x\"].permute(0, 2, 1)\n",
    "            embs_list.append(model.encode_part(inputs).to(device=torch.device('cpu')))\n",
    "                        \n",
    "            labels_list.append(batch[\"label\"].to(device=torch.device('cpu')))\n",
    "    return embs_list, labels_list\n",
    "\n",
    "def cals_map_all(test_loaders, model, device):\n",
    "    model = model.eval()\n",
    "    metr = []\n",
    "    for loader in test_loaders:\n",
    "        e_list, l_list = encode(model, loader, device)\n",
    "        embs = torch.cat(e_list,dim=0).numpy()\n",
    "        lbs = torch.cat(l_list,dim=0).numpy()\n",
    "        metr.append(calc_map(embs, lbs))\n",
    "    return np.mean(metr)\n",
    "\n",
    "def calc_map(X, labels, K = 5):\n",
    "    tree = KDTree(X, leaf_size=40)  # creating kd tree\n",
    "    _, ind = tree.query(X, k=K+1)  # quering nearest items\n",
    "\n",
    "    is_valid_label = (labels[ind[:,1:]] == labels.reshape(-1,1)).astype(int)\n",
    "\n",
    "    cum_sum = np.cumsum(is_valid_label, axis=1)\n",
    "    P_K = cum_sum/np.arange(1, K+1).reshape(1,-1)\n",
    "    AP_K = P_K.sum(axis=1) / np.clip(cum_sum[:,-1],1, K)\n",
    "\n",
    "    return AP_K.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8df7ad0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c232ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu122\n",
      "Requirement already satisfied: torch in d:\\anaconda\\envs\\uv_net\\lib\\site-packages (2.0.1)\n",
      "Requirement already satisfied: torchvision in d:\\anaconda\\envs\\uv_net\\lib\\site-packages (0.15.2)\n",
      "Requirement already satisfied: torchaudio in d:\\anaconda\\envs\\uv_net\\lib\\site-packages (2.0.2)\n",
      "Requirement already satisfied: filelock in d:\\anaconda\\envs\\uv_net\\lib\\site-packages (from torch) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions in d:\\anaconda\\envs\\uv_net\\lib\\site-packages (from torch) (4.7.1)\n",
      "Requirement already satisfied: sympy in d:\\anaconda\\envs\\uv_net\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in d:\\anaconda\\envs\\uv_net\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in d:\\anaconda\\envs\\uv_net\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: numpy in d:\\anaconda\\envs\\uv_net\\lib\\site-packages (from torchvision) (1.25.1)\n",
      "Requirement already satisfied: requests in d:\\anaconda\\envs\\uv_net\\lib\\site-packages (from torchvision) (2.31.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in d:\\anaconda\\envs\\uv_net\\lib\\site-packages (from torchvision) (9.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\anaconda\\envs\\uv_net\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\anaconda\\envs\\uv_net\\lib\\site-packages (from requests->torchvision) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda\\envs\\uv_net\\lib\\site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\anaconda\\envs\\uv_net\\lib\\site-packages (from requests->torchvision) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\envs\\uv_net\\lib\\site-packages (from requests->torchvision) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in d:\\anaconda\\envs\\uv_net\\lib\\site-packages (from sympy->torch) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -orch (d:\\anaconda\\envs\\uv_net\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -qdm (d:\\anaconda\\envs\\uv_net\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (d:\\anaconda\\envs\\uv_net\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -qdm (d:\\anaconda\\envs\\uv_net\\lib\\site-packages)\n",
      "DEPRECATION: vtk -PKG-VERSION has a non-standard version number. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of vtk or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu122"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cbf129e6-61eb-466b-a0b4-15a4b7be81b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "args = AttrDict({})\n",
    "args.batch_size = 128\n",
    "args.random_rotate = False\n",
    "args.num_workers = 150\n",
    "args.checkpoint = 'D:/NIR/results/classif3/0808/094121/best.ckpt'\n",
    "device = torch.device('cpu') #изначально было ('cuda:2'), может потом стоит поменять обратно, если чет не будет получаться опять\n",
    "\n",
    "model = Classification.load_from_checkpoint(args.checkpoint).model.to(device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16fd0efc-cdea-41ec-8be7-4489feee1fdc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\NIR\\SolidLetters\\graph_with_eattr\\a_Nova Script_lower.bin True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2600 [00:00<?, ?it/s]D:\\Anaconda\\envs\\uv_net\\lib\\site-packages\\dgl\\base.py:45: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.\n",
      "  return warnings.warn(message, category=category, stacklevel=1)\n",
      "100%|██████████| 2600/2600 [00:27<00:00, 94.02it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done loading 2600 files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\uv_net\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:560: UserWarning: This DataLoader will create 150 worker processes in total. Our suggested max number of worker in current system is 4 (`cpuset` is not taken into account), which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\NIR\\SolidLetters\\graph_with_eattr\\a_Saira SemiCondensed SemiBold_upper.bin True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2600 [00:00<?, ?it/s]D:\\Anaconda\\envs\\uv_net\\lib\\site-packages\\dgl\\base.py:45: DGLWarning: You are loading a graph file saved by old version of dgl.              Please consider saving it again with the current format.\n",
      "  return warnings.warn(message, category=category, stacklevel=1)\n",
      "100%|██████████| 2600/2600 [00:27<00:00, 93.74it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done loading 2600 files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\uv_net\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:560: UserWarning: This DataLoader will create 150 worker processes in total. Our suggested max number of worker in current system is 4 (`cpuset` is not taken into account), which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "fnm_list = os.listdir('D:/NIR/SolidLetters/graph_with_eattr')\n",
    "N_ITEMS_PER_CLASS = 100\n",
    "\n",
    "# creating loaders for SolidLetters dataset quering\n",
    "test_loaders = []\n",
    "for case in ('lower', 'upper'):\n",
    "    ncl, fnm_labels = sample_from_letter(fnm_list, N_ITEMS_PER_CLASS, case)\n",
    "    dset = RankingDataset('D:/NIR/SolidLetters/graph_with_eattr/', \n",
    "                           fnm_labels, \n",
    "                           ncl)\n",
    "    test_loaders.append(dset.get_dataloader(batch_size=args.batch_size, shuffle=False, num_workers=args.num_workers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b5df48b4-75dd-4750-a300-eeee8a700cba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9c756c-7bad-4322-81d1-7d26452213eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "# calculating metric\n",
    "tqdm(cals_map_all(test_loaders, model, device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855a75a1-2153-488c-a9f5-b84a87bb596b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adeaae9e-ab5e-4421-9e82-5b71afddf956",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb28d2f3-730b-4f41-a138-512dbed48c7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849fdc6d-da14-410a-83c3-1ca49291c51c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7708ec6-ccb9-4b8c-b62f-583e4e21ff56",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5800/157727706.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'timeit'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'calc_map(X, labels)\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Anaconda\\envs\\uv_net\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[1;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[0;32m   2470\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2471\u001b[0m                 \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2472\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2473\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2474\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\uv_net\\lib\\site-packages\\decorator.py\u001b[0m in \u001b[0;36mfun\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mkwsyntax\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m                 \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mcaller\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mextras\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    233\u001b[0m     \u001b[0mfun\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m     \u001b[0mfun\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\uv_net\\lib\\site-packages\\IPython\\core\\magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f, *a, **k)\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[1;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 187\u001b[1;33m         \u001b[0mcall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    188\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\uv_net\\lib\\site-packages\\IPython\\core\\magics\\execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[1;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[0;32m   1178\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m                 \u001b[0mnumber\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m \u001b[1;33m**\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1180\u001b[1;33m                 \u001b[0mtime_number\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumber\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1181\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mtime_number\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m0.2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\uv_net\\lib\\site-packages\\IPython\\core\\magics\\execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[1;34m(self, number)\u001b[0m\n\u001b[0;32m    167\u001b[0m         \u001b[0mgc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 169\u001b[1;33m             \u001b[0mtiming\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    170\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mgcold\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<magic-timeit>\u001b[0m in \u001b[0;36minner\u001b[1;34m(_it, _timer)\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "calc_map(X, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d631165a-6ddc-4844-92db-f675e16b1262",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.5 ms ± 10.4 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "calc_map(X, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b137c1da-3944-4667-a2f4-a9be17053fa9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
